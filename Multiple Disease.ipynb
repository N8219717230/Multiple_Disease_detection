{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc9e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "327b9c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# your code goes here\n",
    "\n",
    "# reset the warnings filter (optional)\n",
    "warnings.filterwarnings(\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5326a1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"heart_disease_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea216650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0920cf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b73436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop([\"target\"],axis = 1)\n",
    "y =df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38da865b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((212, 13), (91, 13))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=2023)\n",
    "X_train.shape ,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f46f621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy Score 0.8351648351648352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.82        46\n",
      "           1       0.79      0.91      0.85        45\n",
      "\n",
      "    accuracy                           0.84        91\n",
      "   macro avg       0.84      0.84      0.83        91\n",
      "weighted avg       0.84      0.84      0.83        91\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitish Thakur\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "ls =LogisticRegression().fit(X_train,y_train)\n",
    "y_pred = ls.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print(\"Acuracy Score\"  ,acc )\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9960d312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "0        0   0     1  \n",
       "1        0   0     2  \n",
       "2        2   0     2  \n",
       "3        2   0     2  \n",
       "4        2   0     2  \n",
       "..     ...  ..   ...  \n",
       "298      1   0     3  \n",
       "299      1   0     3  \n",
       "300      1   2     3  \n",
       "301      1   1     3  \n",
       "302      1   1     2  \n",
       "\n",
       "[303 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be55f631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6923076923076923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71        46\n",
      "           1       0.71      0.64      0.67        45\n",
      "\n",
      "    accuracy                           0.69        91\n",
      "   macro avg       0.69      0.69      0.69        91\n",
      "weighted avg       0.69      0.69      0.69        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=4).fit(X_train,y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred_knn))\n",
    "print(classification_report(y_test,y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9b1758e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7252747252747253\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        46\n",
      "           1       0.71      0.76      0.73        45\n",
      "\n",
      "    accuracy                           0.73        91\n",
      "   macro avg       0.73      0.73      0.73        91\n",
      "weighted avg       0.73      0.73      0.73        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nv = MultinomialNB().fit(X_train,y_train)\n",
    "y_pred_nv = nv.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred_nv))\n",
    "print(classification_report(y_test,y_pred_nv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69b68572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8351648351648352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.74      0.82        46\n",
      "           1       0.78      0.93      0.85        45\n",
      "\n",
      "    accuracy                           0.84        91\n",
      "   macro avg       0.85      0.84      0.83        91\n",
      "weighted avg       0.85      0.84      0.83        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rd = RandomForestClassifier().fit(X_train,y_train)\n",
    "y_pred_rd = rd.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred_rd))\n",
    "print(classification_report(y_test,y_pred_rd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42b35e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "001121c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/92\n",
      "7/7 [==============================] - 3s 3ms/step - loss: 1.3640 - accuracy: 0.4906\n",
      "Epoch 2/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.5660\n",
      "Epoch 3/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.5660\n",
      "Epoch 4/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.5660\n",
      "Epoch 5/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.5896\n",
      "Epoch 6/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.6509\n",
      "Epoch 7/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6792\n",
      "Epoch 8/92\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6250 - accuracy: 0.6604\n",
      "Epoch 9/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6611 - accuracy: 0.6085\n",
      "Epoch 10/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.7028\n",
      "Epoch 11/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6260 - accuracy: 0.6840\n",
      "Epoch 12/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.7123\n",
      "Epoch 13/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6071 - accuracy: 0.7123\n",
      "Epoch 14/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.7170\n",
      "Epoch 15/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6044 - accuracy: 0.7217\n",
      "Epoch 16/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.7075\n",
      "Epoch 17/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.7264\n",
      "Epoch 18/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.7028\n",
      "Epoch 19/92\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.6934\n",
      "Epoch 20/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.7123\n",
      "Epoch 21/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7123\n",
      "Epoch 22/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.7358\n",
      "Epoch 23/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5813 - accuracy: 0.7217\n",
      "Epoch 24/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.7500\n",
      "Epoch 25/92\n",
      "7/7 [==============================] - 0s 727us/step - loss: 0.5781 - accuracy: 0.7358\n",
      "Epoch 26/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.7406\n",
      "Epoch 27/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.7406\n",
      "Epoch 28/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5693 - accuracy: 0.7311\n",
      "Epoch 29/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7406\n",
      "Epoch 30/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7594\n",
      "Epoch 31/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5652 - accuracy: 0.7689\n",
      "Epoch 32/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7547\n",
      "Epoch 33/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5538 - accuracy: 0.7547\n",
      "Epoch 34/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7783\n",
      "Epoch 35/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7736\n",
      "Epoch 36/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7406\n",
      "Epoch 37/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5935 - accuracy: 0.7028\n",
      "Epoch 38/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.7736\n",
      "Epoch 39/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7547\n",
      "Epoch 40/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7642\n",
      "Epoch 41/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5550 - accuracy: 0.7783\n",
      "Epoch 42/92\n",
      "7/7 [==============================] - 0s 588us/step - loss: 0.5439 - accuracy: 0.7783\n",
      "Epoch 43/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7877\n",
      "Epoch 44/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7830\n",
      "Epoch 45/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7877\n",
      "Epoch 46/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7642\n",
      "Epoch 47/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7877\n",
      "Epoch 48/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7972\n",
      "Epoch 49/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7642\n",
      "Epoch 50/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7972\n",
      "Epoch 51/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7925\n",
      "Epoch 52/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.8019\n",
      "Epoch 53/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7925\n",
      "Epoch 54/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.8019\n",
      "Epoch 55/92\n",
      "7/7 [==============================] - 0s 692us/step - loss: 0.4927 - accuracy: 0.8113\n",
      "Epoch 56/92\n",
      "7/7 [==============================] - 0s 523us/step - loss: 0.5265 - accuracy: 0.7830\n",
      "Epoch 57/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.8113\n",
      "Epoch 58/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.8113\n",
      "Epoch 59/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.8255\n",
      "Epoch 60/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7500\n",
      "Epoch 61/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7500\n",
      "Epoch 62/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.8160\n",
      "Epoch 63/92\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.8160\n",
      "Epoch 64/92\n",
      "7/7 [==============================] - 0s 806us/step - loss: 0.4892 - accuracy: 0.8443\n",
      "Epoch 65/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7830\n",
      "Epoch 66/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.8396\n",
      "Epoch 67/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.8160\n",
      "Epoch 68/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.8160\n",
      "Epoch 69/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.8255\n",
      "Epoch 70/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.8396\n",
      "Epoch 71/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.8396\n",
      "Epoch 72/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.8066\n",
      "Epoch 73/92\n",
      "7/7 [==============================] - 0s 551us/step - loss: 0.4902 - accuracy: 0.8208\n",
      "Epoch 74/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.8019\n",
      "Epoch 75/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7830\n",
      "Epoch 76/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7264\n",
      "Epoch 77/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7925\n",
      "Epoch 78/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.8396\n",
      "Epoch 79/92\n",
      "7/7 [==============================] - 0s 682us/step - loss: 0.4597 - accuracy: 0.8538\n",
      "Epoch 80/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.8255\n",
      "Epoch 81/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.8349\n",
      "Epoch 82/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.8208\n",
      "Epoch 83/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.8302\n",
      "Epoch 84/92\n",
      "7/7 [==============================] - 0s 721us/step - loss: 0.4549 - accuracy: 0.8396\n",
      "Epoch 85/92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 582us/step - loss: 0.4694 - accuracy: 0.8208\n",
      "Epoch 86/92\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8396\n",
      "Epoch 87/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.8349\n",
      "Epoch 88/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.8491\n",
      "Epoch 89/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7925\n",
      "Epoch 90/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6034 - accuracy: 0.7925\n",
      "Epoch 91/92\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.8302\n",
      "Epoch 92/92\n",
      "7/7 [==============================] - 0s 626us/step - loss: 0.5071 - accuracy: 0.8066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ba310afe20>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1000,activation=\"relu\"),\n",
    "    keras.layers.Dense(100,activation =\"relu\"),\n",
    "    keras.layers.Dense(10,activation =\"relu\"),\n",
    "    keras.layers.Dense(1,activation =\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss =\"binary_crossentropy\",\n",
    "              metrics = [\"accuracy\",])\n",
    "model.fit(X_train,y_train,epochs = 92)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec0c48",
   "metadata": {},
   "source": [
    "best result we get with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "315560ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mdump(X,\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_heart.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "pickle.dump(X,open(\"X_heart.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf1ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60dcf9c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mdump(ls ,\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogistic.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "pickle.dump(ls ,open(\"logistic.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be790c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"diabetes.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "452866b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15c117f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =df1.drop([\"Outcome\"],axis= 1)\n",
    "y =df1[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44bbf65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "0                       0.627   50  \n",
       "1                       0.351   31  \n",
       "2                       0.672   32  \n",
       "3                       0.167   21  \n",
       "4                       2.288   33  \n",
       "..                        ...  ...  \n",
       "763                     0.171   63  \n",
       "764                     0.340   27  \n",
       "765                     0.245   30  \n",
       "766                     0.349   47  \n",
       "767                     0.315   23  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "804b6c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 8), (154, 8))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2023)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "639aa287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy Score 0.7597402597402597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82        97\n",
      "           1       0.72      0.58      0.64        57\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.75      0.72      0.73       154\n",
      "weighted avg       0.76      0.76      0.75       154\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitish Thakur\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "ls =LogisticRegression().fit(X_train,y_train)\n",
    "y_pred = ls.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print(\"Acuracy Score\"  ,acc )\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "310cd4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7337662337662337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80        97\n",
      "           1       0.68      0.53      0.59        57\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.72      0.69      0.70       154\n",
      "weighted avg       0.73      0.73      0.72       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=9).fit(X_train,y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred_knn))\n",
    "print(classification_report(y_test,y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "255eb1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5844155844155844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.70      0.68        97\n",
      "           1       0.43      0.39      0.41        57\n",
      "\n",
      "    accuracy                           0.58       154\n",
      "   macro avg       0.55      0.54      0.54       154\n",
      "weighted avg       0.58      0.58      0.58       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nv = MultinomialNB().fit(X_train,y_train)\n",
    "y_pred_nv = nv.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred_nv))\n",
    "print(classification_report(y_test,y_pred_nv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a1995c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.79        97\n",
      "           1       0.66      0.54      0.60        57\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.69      0.70       154\n",
      "weighted avg       0.72      0.73      0.72       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rd = RandomForestClassifier().fit(X_train,y_train)\n",
    "y_pred_rd = rd.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred_rd))\n",
    "print(classification_report(y_test,y_pred_rd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "32b72479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 2.1682 - accuracy: 0.5700\n",
      "Epoch 2/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8671 - accuracy: 0.5879\n",
      "Epoch 3/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7841 - accuracy: 0.6433\n",
      "Epoch 4/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.6547\n",
      "Epoch 5/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8749 - accuracy: 0.6319\n",
      "Epoch 6/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.6710\n",
      "Epoch 7/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.6629\n",
      "Epoch 8/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.6531\n",
      "Epoch 9/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.6938\n",
      "Epoch 10/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.7052\n",
      "Epoch 11/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.8017 - accuracy: 0.6303\n",
      "Epoch 12/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6629\n",
      "Epoch 13/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7036\n",
      "Epoch 14/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7150\n",
      "Epoch 15/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.6922\n",
      "Epoch 16/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6673 - accuracy: 0.6466\n",
      "Epoch 17/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7150\n",
      "Epoch 18/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.7101\n",
      "Epoch 19/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6825 - accuracy: 0.6824\n",
      "Epoch 20/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7134\n",
      "Epoch 21/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.6954\n",
      "Epoch 22/80\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7068\n",
      "Epoch 23/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7459\n",
      "Epoch 24/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7264\n",
      "Epoch 25/80\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.6922\n",
      "Epoch 26/80\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7248\n",
      "Epoch 27/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.7036\n",
      "Epoch 28/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.6906\n",
      "Epoch 29/80\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7150\n",
      "Epoch 30/80\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7101\n",
      "Epoch 31/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.7215\n",
      "Epoch 32/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.7492\n",
      "Epoch 33/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7199\n",
      "Epoch 34/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7231\n",
      "Epoch 35/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7524\n",
      "Epoch 36/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.6824\n",
      "Epoch 37/80\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7280\n",
      "Epoch 38/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7524\n",
      "Epoch 39/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7427\n",
      "Epoch 40/80\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7410\n",
      "Epoch 41/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7410\n",
      "Epoch 42/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7264\n",
      "Epoch 43/80\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.7557\n",
      "Epoch 44/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7410\n",
      "Epoch 45/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7362\n",
      "Epoch 46/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7443\n",
      "Epoch 47/80\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7492\n",
      "Epoch 48/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7394\n",
      "Epoch 49/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7264\n",
      "Epoch 50/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7166\n",
      "Epoch 51/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7345\n",
      "Epoch 52/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7231\n",
      "Epoch 53/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7199\n",
      "Epoch 54/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7590\n",
      "Epoch 55/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7557\n",
      "Epoch 56/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7622\n",
      "Epoch 57/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7492\n",
      "Epoch 58/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7264\n",
      "Epoch 59/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7476\n",
      "Epoch 60/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7476\n",
      "Epoch 61/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7557\n",
      "Epoch 62/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7182\n",
      "Epoch 63/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7427\n",
      "Epoch 64/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7557\n",
      "Epoch 65/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7427\n",
      "Epoch 66/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7557\n",
      "Epoch 67/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7476\n",
      "Epoch 68/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7410\n",
      "Epoch 69/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7541\n",
      "Epoch 70/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7329\n",
      "Epoch 71/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5532 - accuracy: 0.7264\n",
      "Epoch 72/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7378\n",
      "Epoch 73/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7524\n",
      "Epoch 74/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7736\n",
      "Epoch 75/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7655\n",
      "Epoch 76/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7313\n",
      "Epoch 77/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7573\n",
      "Epoch 78/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7264\n",
      "Epoch 79/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7752\n",
      "Epoch 80/80\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28fcf497e80>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1000,activation=\"relu\"),\n",
    "    keras.layers.Dense(100,activation =\"relu\"),\n",
    "    keras.layers.Dense(10,activation =\"relu\"),\n",
    "    keras.layers.Dense(1,activation =\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss =\"binary_crossentropy\",\n",
    "              metrics = [\"accuracy\",])\n",
    "model.fit(X_train,y_train,epochs = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a67eb",
   "metadata": {},
   "source": [
    "we have get the best result with Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b84a1b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitish Thakur\\AppData\\Local\\Temp\\ipykernel_28020\\3489218455.py:1: ResourceWarning: unclosed file <_io.BufferedWriter name='X_diabeties.pkl'>\n",
      "  pickle.dump(X,open(\"X_diabeties.pkl\",\"wb\"))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(X,open(\"X_diabeties.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "86a2116f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitish Thakur\\AppData\\Local\\Temp\\ipykernel_28020\\3242615163.py:1: ResourceWarning: unclosed file <_io.BufferedWriter name='X_dieases_random.pkl'>\n",
      "  pickle.dump(ls,open(\"X_dieases_random.pkl\",\"wb\"))\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(ls,open(\"X_dieases_random.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15afa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
